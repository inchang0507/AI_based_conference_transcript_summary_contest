{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "1104_for_git_LG_sum.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "37f6d2ed47ad4e34b4b4abfb33a4da69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_310021e062ca4bc6b9da124809cff436",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_20ba95f02d204418a41a83f429231dff",
              "IPY_MODEL_94659f37437d4e5b9d13e2255a608636",
              "IPY_MODEL_41023d2c285c4cd2b9c39ccfdd3b51c0"
            ]
          }
        },
        "310021e062ca4bc6b9da124809cff436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20ba95f02d204418a41a83f429231dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e3691cba2e554a5986a66772feae8ec5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_921379b2651a49bd892a3d18e950e176"
          }
        },
        "94659f37437d4e5b9d13e2255a608636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dacce9c9394c4ebf860fde51a66d4896",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 495659091,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 495659091,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b42d65cbc25243fc8338d2e481c4f741"
          }
        },
        "41023d2c285c4cd2b9c39ccfdd3b51c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4662a23fcf8d471a9a612fe91c958a4e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 473M/473M [00:14&lt;00:00, 36.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e137421e9714734966c978ce91015f8"
          }
        },
        "e3691cba2e554a5986a66772feae8ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "921379b2651a49bd892a3d18e950e176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dacce9c9394c4ebf860fde51a66d4896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b42d65cbc25243fc8338d2e481c4f741": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4662a23fcf8d471a9a612fe91c958a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e137421e9714734966c978ce91015f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNo19C9U4Fpm",
        "outputId": "646086ec-3168-4ec4-9d0e-4bc5ecca4f98"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV6dvr3fD1tb"
      },
      "source": [
        "#### ※ 파라미터 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyyz2WCyD1tc"
      },
      "source": [
        "# 파라미터 설정\n",
        "train_pct = 1 # 학습용 데이터 퍼센트\n",
        "test_pct = 0 # 검증용 데이터 퍼센트\n",
        "max_length = 1000 # 인코딩 입력 데이터 최대 길이\n",
        "label_len = 325 # 디코딩 입력 데이터 최대 길이\n",
        "batch_size = 4 \n",
        "\n",
        "EPOCHS = 5\n",
        "warmup_ratio = 0.1 # 학습 스케줄러 사용 시 warm_up 비율\n",
        "learning_rate = 1e-4\n",
        "max_grad_norm = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UN1A0sBLoSB"
      },
      "source": [
        "## 1. 패키지 로드 및 데이터 로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjXbxTubDt9B"
      },
      "source": [
        "### 1-1 필요 패키지 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh1by_sED2rC"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install einops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8pkXMZCi2kE"
      },
      "source": [
        "import transformers\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import requests\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.utils as torch_utils\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "import json\n",
        "from glob import glob\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "from transformers import BartForConditionalGeneration\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "\n",
        "# 토크나이저 설치\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-summarization')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azvD5_dSLyKC",
        "outputId": "7a137fdf-d7aa-467a-cdd6-3e5df6d1ba12"
      },
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0,1\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('Device:', device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lre0ph3rB3n1"
      },
      "source": [
        "### 1-2 데이터 로드\n",
        "- json 파일 로드 후 데이터를 데이터 프레임 형태로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV_V70vmLfsp"
      },
      "source": [
        "DIR = \"/content/drive/MyDrive/LG_자연어/data\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dc78280"
      },
      "source": [
        "# 데이터 로드 및 데이터 프레임 형태로 전환\n",
        "\n",
        "TRAIN_SOURCE = os.path.join(DIR, \"train.json\")\n",
        "TEST_SOURCE = os.path.join(DIR, \"test.json\")\n",
        "\n",
        "with open(TRAIN_SOURCE) as f:\n",
        "    TRAIN_DATA = json.loads(f.read())\n",
        "    \n",
        "with open(TEST_SOURCE) as f:\n",
        "    TEST_DATA = json.loads(f.read())\n",
        "\n",
        "\n",
        "# DataFrame 형태로 변환\n",
        "train = pd.DataFrame(columns=['uid','agenda','title', 'context', 'summary'])\n",
        "\n",
        "uid = 1000\n",
        "for data in TRAIN_DATA:\n",
        "    for agenda in data['context'].keys():\n",
        "        context = ''\n",
        "        for line in data['context'][agenda]:\n",
        "            context += data['context'][agenda][line]\n",
        "            context += ' '\n",
        "\n",
        "        train.loc[uid, 'uid'] = uid\n",
        "        train.loc[uid, 'title'] = data['title']\n",
        "        train.loc[uid, 'agenda'] = agenda\n",
        "        train.loc[uid, 'context'] = context[:-1]\n",
        "        train.loc[uid, 'summary'] = data['label'][agenda]['summary']\n",
        "        uid += 1\n",
        "\n",
        "test = pd.DataFrame(columns=['uid','agenda', 'title', 'context'])\n",
        "uid = 2000\n",
        "for data in TEST_DATA:\n",
        "    for agenda in data['context'].keys():\n",
        "        context = ''\n",
        "        \n",
        "        for line in data['context'][agenda]:\n",
        "            context += data['context'][agenda][line]\n",
        "            context += ' '\n",
        "        test.loc[uid, 'uid'] = uid\n",
        "        test.loc[uid, 'title'] = data['title']\n",
        "        test.loc[uid, 'agenda'] = agenda\n",
        "        test.loc[uid, 'context'] = context[:-1]\n",
        "        uid += 1\n",
        "test['summary'] = '공백'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5xPMxuHZ6Rf"
      },
      "source": [
        "## 2. 전처리\n",
        "- 특수문자 제거\n",
        "- 문장 길이 측정 : 1) 인코더 및 디코더 입력 길이 판단 시 사용\n",
        "- 특징 학습을 위한 레이블 설정 : 본문 길이, 요약문 길이, 요약문 끝문장의 형태를 대상으로 군집화를 수행하여 해당 군집 번호를 레이블로 사용 --> 해당 레이블을 함께 학습시키고 발생하는 손실값을 합하여 요약에 대한 학습과 문장 특징에 대한 학습을 동시에 진행 --> 특징을 고려하는 보다 안정적인 요약 모델을 생성하는 것이 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J9U3DZ3Z_vu"
      },
      "source": [
        "### 2-1 텍스트 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w65i3n6bQ-sY"
      },
      "source": [
        "# 전체 문서 기준, 높은 빈도수를 나타내는 문장을 필요없는 문장으로 판단하여 제거\n",
        "\n",
        "text_list = []\n",
        "for i in train['context']:\n",
        "    for j in i.split('.')[:-1]:\n",
        "        text_list.append(j)\n",
        "\n",
        "text_value_counts = pd.DataFrame(pd.DataFrame(text_list)[0].value_counts()).reset_index()\n",
        "\n",
        "remove_list = list(text_value_counts[text_value_counts[0]>=360]['index'])\n",
        "\n",
        "def split_dot(df):\n",
        "    return df.split('.')\n",
        "\n",
        "train['context_split'] = train['context'].apply(split_dot)\n",
        "test['context_split'] = test['context'].apply(split_dot)\n",
        "\n",
        "train['context_split_removed'] = train['context_split'].apply(lambda x: [a for a in x if a not in remove_list])\n",
        "test['context_split_removed'] = test['context_split'].apply(lambda x: [a for a in x if a not in remove_list])\n",
        "\n",
        "\n",
        "train['context'] = train['context_split_removed'].apply(lambda x: '.'.join(x))\n",
        "test['context'] = test['context_split_removed'].apply(lambda x: '.'.join(x))\n",
        "\n",
        "train = train.drop(['context_split','context_split_removed'],axis=1)\n",
        "test = test.drop(['context_split','context_split_removed'],axis=1)\n",
        "\n",
        "train['total'] = train.title + ' <t> ' + train.context\n",
        "test['total'] = test.title + ' <t> ' + test.context"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "15Gz64y5Cz9u",
        "scrolled": true,
        "outputId": "35a60b6a-a296-49d5-e06c-37ea930163e5"
      },
      "source": [
        "in_df = train.copy()\n",
        "in_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>agenda</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>summary</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>1000</td>\n",
              "      <td>AGENDA_1</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
              "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제207회 완주군의회 임시회 제...</td>\n",
              "      <td>제207회 완주군의회 임시회 제1차 본회의 개의 선포.</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 &lt;t&gt; 의석을 정돈하여 주시기...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>1001</td>\n",
              "      <td>AGENDA_2</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
              "      <td>의사팀장 수고하셨습니다. 먼저 의사일정 제1항 제207회 완주군의회 임시회 회기 결...</td>\n",
              "      <td>제207회 완주군의회 임시회 회기는 8월 26일부터 9월 4일까지 10일간으로 가결됨.</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 &lt;t&gt; 의사팀장 수고하셨습니다...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002</th>\n",
              "      <td>1002</td>\n",
              "      <td>AGENDA_3</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
              "      <td>다음은 의사일정 제2항 제207회 완주군의회 임시회 회의록 서명의원 선출의 건을 상...</td>\n",
              "      <td>제207회 완주군의회 임시회 회의록 서명의원으로 최등원 의원과 박웅배 의원이 선출됨.</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 &lt;t&gt; 다음은 의사일정 제2항...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003</th>\n",
              "      <td>1003</td>\n",
              "      <td>AGENDA_4</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
              "      <td>다음은 의사일정 제3항 본회의 휴회의 건을 상정합니다. 상임의원회 의정활동을 위하여...</td>\n",
              "      <td>8월 27일부터 9월 3일까지 8일간 휴회가 가결됨. 제2차 본회의는 9월 4일 오...</td>\n",
              "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 &lt;t&gt; 다음은 의사일정 제3항...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>1004</td>\n",
              "      <td>AGENDA_1</td>\n",
              "      <td>제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록</td>\n",
              "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제251회 완주군의회 제1차 정...</td>\n",
              "      <td>제251회 완주군의회 제1차 정례회 제1차 본회의 개의 선포.</td>\n",
              "      <td>제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록 &lt;t&gt; 의석을 정...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       uid  ...                                              total\n",
              "1000  1000  ...  제207회 완주군의회(임시회) 제 1 차 본회의회의록 <t> 의석을 정돈하여 주시기...\n",
              "1001  1001  ...  제207회 완주군의회(임시회) 제 1 차 본회의회의록 <t> 의사팀장 수고하셨습니다...\n",
              "1002  1002  ...  제207회 완주군의회(임시회) 제 1 차 본회의회의록 <t> 다음은 의사일정 제2항...\n",
              "1003  1003  ...  제207회 완주군의회(임시회) 제 1 차 본회의회의록 <t> 다음은 의사일정 제3항...\n",
              "1004  1004  ...  제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록 <t> 의석을 정...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7K1p5JQB3WR"
      },
      "source": [
        "# 특수문자 제거 함수\n",
        "def clean_text(text):\n",
        "    text = re.sub(\"\\(\", ' ', text)\n",
        "    text = re.sub(\"\\)\", ' ', text)\n",
        "    text = re.sub(\"[『 』]\", ' ', text)\n",
        "    return text\n",
        "\n",
        "in_df[\"total_clean\"] = in_df[\"total\"].apply(clean_text)\n",
        "in_df[\"summary_clean\"] = in_df[\"summary\"].apply(clean_text)\n",
        "test[\"total_clean\"] = test[\"total\"].apply(clean_text)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IribPID0Zy1u"
      },
      "source": [
        "# 문장의 처음과 끝에 사인을 삽입\n",
        "def sos_eos(df):\n",
        "    return '<s> '+df+' </s>'\n",
        "\n",
        "in_df['total_clean'] = in_df['total_clean'].apply(sos_eos)\n",
        "in_df['summary_clean'] = in_df['summary_clean'].apply(sos_eos)\n",
        "\n",
        "test['total_clean'] = test['total_clean'].apply(sos_eos)\n",
        "test['summary'] = test['summary'].apply(sos_eos)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR0CG-hSYhzO"
      },
      "source": [
        "### 2-2 군집화를 활용한 문장 특징 레이블 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDMyMJVQaO7I"
      },
      "source": [
        "# 문장 길이 출력 함수 \n",
        "def cal_len(text):\n",
        "    return len(text.split())\n",
        "\n",
        "in_df['context_len'] = in_df['total_clean'].apply(cal_len)\n",
        "in_df['target_len'] = in_df['summary_clean'].apply(cal_len)\n",
        "in_df['target_len_total'] = in_df['summary'].apply(lambda x: len(x))\n",
        "test['len'] = test['total_clean'].apply(cal_len)\n",
        "\n",
        "# Agenda 레이블 인코딩\n",
        "last_sumtext = list(train[\"agenda\"].unique())\n",
        "in_df[\"agenda_label\"] = train[\"agenda\"].apply(lambda x: last_sumtext.index(x))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbi8ioO9WC5o",
        "outputId": "06f666ce-e9ac-415f-8f2f-a467480a83a3"
      },
      "source": [
        "k = StandardScaler().fit_transform(in_df[['context_len','target_len_total','agenda_label']])\n",
        "\n",
        "kmeans = KMeans(n_clusters=9,random_state=0)\n",
        "labels = kmeans.fit_predict(k)\n",
        "in_df['label'] = labels\n",
        "\n",
        "print('실루엣 스코어 : {0:.3f}'.format(silhouette_score(k,labels)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "실루엣 스코어 : 0.408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxXIY1PLQTFZ"
      },
      "source": [
        "### 2-3 학습 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyPNOe7hbyXl"
      },
      "source": [
        "class Summary_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels, lasttext=None):\n",
        "        self.encodings = encodings[\"input_ids\"]\n",
        "        self.token_type = encodings[\"token_type_ids\"]\n",
        "        self.masking = encodings[\"attention_mask\"]\n",
        "        self.labels = labels\n",
        "        self.lasttext = lasttext            \n",
        "            \n",
        "    def __getitem__(self, idx):\n",
        "        item = {}\n",
        "        if self.encodings[idx][-1]!=3:\n",
        "            self.encodings[idx][-1] = 1 \n",
        "            \n",
        "        if self.labels['input_ids'][idx][-1] !=3:\n",
        "            self.labels['input_ids'][idx][-1] = 1\n",
        "        \n",
        "        if self.lasttext is not None:\n",
        "            item['last_text'] = torch.tensor(self.lasttext.iloc[idx])\n",
        "        \n",
        "        item['input_ids'] = torch.tensor(self.encodings[idx])\n",
        "        item['attention_mask'] = torch.tensor(self.masking[idx])\n",
        "        item['token_type_ids'] = torch.tensor(self.token_type[idx])\n",
        "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L73zBQ8i2kG",
        "scrolled": true
      },
      "source": [
        "## 학습 및 검증 세트 설정\n",
        "in_df = in_df.sample(len(in_df), random_state=20)\n",
        "train_sub = int(len(in_df) * train_pct)\n",
        "# test_sub = int(len(in_df) * test_pct) + train_sub\n",
        "\n",
        "train_df = in_df[0:train_sub]\n",
        "test_df = in_df[train_sub:]\n",
        "# val_df = in_df[test_sub:]\n",
        "\n",
        "train_texts = list(train_df['total_clean'])\n",
        "test_texts = list(test_df['total_clean'])\n",
        "# val_texts = list(val_df['text'])\n",
        "\n",
        "train_decode = list(train_df['summary_clean'])\n",
        "test_decode = list(test_df['summary_clean'])\n",
        "# val_decode = list(val_df['summary'])\n",
        "\n",
        "test_df_texts = list(test['total_clean'])\n",
        "test_df_decode = list(test['summary'])\n",
        "\n",
        "\n",
        "## 토크나이징\n",
        "train_encodings = tokenizer(train_texts,max_length=max_length, truncation=True, padding='max_length',add_special_tokens = True,return_tensors=\"pt\")\n",
        "# test_encodings = tokenizer(test_texts,max_length=max_length, truncation=True, padding=True)\n",
        "train_labels = tokenizer(train_decode,max_length=label_len, truncation=True, padding='max_length',add_special_tokens = True,return_tensors=\"pt\")\n",
        "# test_labels = tokenizer(test_decode,max_length=50, truncation=True, padding=True)\n",
        "\n",
        "test_df_encodings = tokenizer(test_df_texts,max_length=max_length, truncation=True, padding='max_length',add_special_tokens = True,return_tensors=\"pt\")\n",
        "test_df_labels = tokenizer(test_df_decode,max_length=label_len, truncation=True, padding=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvEmd2ENi2kI"
      },
      "source": [
        "train_dataset = Summary_dataset(train_encodings, train_labels, lasttext=in_df[\"label\"])\n",
        "# test_dataset = Summary_dataset(test_encodings, test_labels)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=5, shuffle=True)\n",
        "# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwoV_MpNP3vg"
      },
      "source": [
        "## 3. 모델 설계\n",
        "#### 모델 특징\n",
        "- 한 모델에서 요약에 대한 학습과 문장 특징 학습(군집화를 통해 구한 클래스에 대한 분류 학습)을 동시에 진행\n",
        "- 각 학습을 통해 구해진 loss를 A + (B/10) 비율로 합산하고 이를 역전파를 통해 업데이트\n",
        "- 문장의 특징(context의 길이, 요약문의 길이, 안건)을 함께 학습하기 때문에 출력문의 길이와 형태를 보다 잘 나타내어 ***안정적인 학습***이 가능 \n",
        "\n",
        "#### 세부 조정 사항\n",
        "- 주어진 학습데이터가 상대적으로 적기 때문에 인코딩 층, 디코딩 층 각각의 최하단 부분과 출력층까지만 가중치 업데이트 진행\n",
        "- 2 epoch까지 요약문과 문장 특징을 함께 학습하고, 이후 3번의 epoch 요약문 학습만 진행\n",
        "- 학습률 스케줄을 적용하여 처음에는 1e-4로 학습 후 warm ratio 초과시 get_cosine_schedule_with_warmup을 이용하여 학습률 조정\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48,
          "referenced_widgets": [
            "37f6d2ed47ad4e34b4b4abfb33a4da69",
            "310021e062ca4bc6b9da124809cff436",
            "20ba95f02d204418a41a83f429231dff",
            "94659f37437d4e5b9d13e2255a608636",
            "41023d2c285c4cd2b9c39ccfdd3b51c0",
            "e3691cba2e554a5986a66772feae8ec5",
            "921379b2651a49bd892a3d18e950e176",
            "dacce9c9394c4ebf860fde51a66d4896",
            "b42d65cbc25243fc8338d2e481c4f741",
            "4662a23fcf8d471a9a612fe91c958a4e",
            "4e137421e9714734966c978ce91015f8"
          ]
        },
        "id": "LY1FCPRl4Ez2",
        "outputId": "0916ee81-343b-4bac-e2df-019bd71df31e"
      },
      "source": [
        "class BART_Classification(nn.Module):\n",
        "    def __init__(self,n_classes, emb_size=768):\n",
        "        super().__init__()\n",
        "        self.bart_model = BartForConditionalGeneration.from_pretrained('gogamza/kobart-summarization')\n",
        "        self.reduce = Reduce('b n e -> b e', reduction='mean')\n",
        "        self.norm = nn.LayerNorm(n_classes)\n",
        "        self.linear = nn.Linear(emb_size, n_classes)\n",
        "        self.softmax=nn.LogSoftmax(dim=-1)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self,input_,mask_,intrg):\n",
        "        out = self.bart_model.forward(input_,mask_,intrg)\n",
        "        hidden_state = out.encoder_last_hidden_state\n",
        "                \n",
        "        x = self.reduce(hidden_state)\n",
        "        x = self.linear(x)\n",
        "        x = self.norm(x)\n",
        "\n",
        "        x = self.softmax(x)\n",
        "        return x, out\n",
        "\n",
        "model = BART_Classification(in_df[\"label\"].nunique())\n",
        "model = model.to(device)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37f6d2ed47ad4e34b4b4abfb33a4da69",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/473M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NztEl2Xqcs0s"
      },
      "source": [
        "### 3-1 모델 세부 조정\n",
        "\n",
        "##### - KoBART 모델 층 구조\n",
        "- encoding part : 2 ~ 97 / Layer norm 98 ~ 99\n",
        "- decoding part : Embedding, PE  100 ~ 101 / Decoding 층 102 ~ 257 / Layer norm 258~259\n",
        "\n",
        "- 총 개수 259 개\n",
        "\n",
        "##### - 주어진 학습 데이터가 상대적으로 적기 때문에 인코딩 층, 디코딩 층 각각의 최하단 부분과 출력층까지 가중치 업데이트 진행\n",
        "##### - 초기에 1e-4로 학습 후 warm ratio 초과시 get_cosine_schedule_with_warmup을 이용하여 학습률 조정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skYCV1ST_UOM"
      },
      "source": [
        "n=0\n",
        "for name, child in model.named_children():\n",
        "    if n==0:\n",
        "      h=0\n",
        "      for param in child.parameters():\n",
        "        if (95<=h) or (98<=h<=255):\n",
        "            param.requires_grad = False\n",
        "        h+=1\n",
        "    n+=1\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "# optimizer =optim.SGD(model.parameters(), lr=10e-5, momentum=0.9)\n",
        "t_total = len(train_dataloader) * EPOCHS\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf-wAt--EsyK"
      },
      "source": [
        "### 3-2 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zezVCeCvdNel",
        "scrolled": true,
        "outputId": "92404fd4-8038-4a53-cc67-ec09a29d882b"
      },
      "source": [
        "torch.cuda.empty_cache() # 캐시 삭제\n",
        "\n",
        "for Epoch in range(EPOCHS): \n",
        "    train_loss = []\n",
        "    first_time = time.time()\n",
        "    epoch_start = time.time()\n",
        "    model.train()\n",
        "    torch.set_grad_enabled(True)\n",
        "    for batch_idx, data in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "       \n",
        "        input_ = data['input_ids'].long().to(device)\n",
        "        mask_ = data['attention_mask'].long().to(device)\n",
        "        trg_ = data[\"labels\"]\n",
        "        intrg = torch.tensor(trg_[:,:-1]).to(device)\n",
        "        outtrg = torch.tensor(trg_[:,1:]).to(device)\n",
        "        \n",
        "        c_out, out = model.forward(input_,mask_,intrg)\n",
        "#         c_out = c_bart.forward(input_,mask_,intrg)\n",
        "        \n",
        "        _,_,vocab = out[0].size()\n",
        "        out_ = out[0].view(-1,vocab)\n",
        "        outtrg = outtrg.view(-1)\n",
        "\n",
        "        c_loss = criterion(c_out.cpu(),data[\"last_text\"].long().cpu())\n",
        "        \n",
        "\n",
        "        # 2 에폭까지는 함께 학습, 이후 3 에폭은 요약문 대상 학습만 진행\n",
        "        # pad 부분에 대해 손실을 구하지 않도록 설정\n",
        "        if Epoch<2:\n",
        "            loss_ = criterion(out_,outtrg)\n",
        "            nopad = torch.logical_not(torch.eq(outtrg, 3))\n",
        "            nopad = torch.tensor(nopad, dtype=loss_.dtype)\n",
        "            loss_ = nopad * loss_\n",
        "        \n",
        "            loss = torch.sum(loss_)/torch.sum(nopad) + c_loss/10\n",
        "        else: \n",
        "            loss_ = criterion(out_,outtrg)\n",
        "            nopad = torch.logical_not(torch.eq(outtrg, 3))\n",
        "            nopad = torch.tensor(nopad, dtype=loss_.dtype)\n",
        "            loss_ = nopad * loss_\n",
        "        \n",
        "            loss = torch.sum(loss_)/torch.sum(nopad)\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        torch_utils.clip_grad_norm_(model.parameters(),1)\n",
        "        optimizer.step()\n",
        "        \n",
        "        scheduler.step()\n",
        "\n",
        "        if batch_idx%20==0:\n",
        "            second_time = time.time()\n",
        "            print(\"Train Epoch: {} [{}/{}({:.0f}%)]\\tTrain Loss: {:.6f}\\t runtime={:.1f}sec\".format(Epoch, batch_idx * batch_size, train_sub,100.*batch_idx* batch_size/train_sub, loss.item(),(second_time-first_time)))\n",
        "            first_time = second_time\n",
        "            \n",
        "        del input_,mask_,trg_, out, outtrg, loss\n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    epoch_end = time.time()\n",
        "\n",
        "    print(\"Train Epoch Takes {:.2f}min\".format((epoch_end - epoch_start)/60))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/2994(0%)]\tTrain Loss: 12.026088\t runtime=0.9sec\n",
            "Train Epoch: 0 [80/2994(3%)]\tTrain Loss: 11.242523\t runtime=12.2sec\n",
            "Train Epoch: 0 [160/2994(5%)]\tTrain Loss: 9.296627\t runtime=12.2sec\n",
            "Train Epoch: 0 [240/2994(8%)]\tTrain Loss: 7.047321\t runtime=12.2sec\n",
            "Train Epoch: 0 [320/2994(11%)]\tTrain Loss: 4.654191\t runtime=12.2sec\n",
            "Train Epoch: 0 [400/2994(13%)]\tTrain Loss: 2.787152\t runtime=12.2sec\n",
            "Train Epoch: 0 [480/2994(16%)]\tTrain Loss: 1.613371\t runtime=12.3sec\n",
            "Train Epoch: 0 [560/2994(19%)]\tTrain Loss: 0.697777\t runtime=12.2sec\n",
            "Train Epoch: 0 [640/2994(21%)]\tTrain Loss: 0.349504\t runtime=12.2sec\n",
            "Train Epoch: 0 [720/2994(24%)]\tTrain Loss: 0.237136\t runtime=12.2sec\n",
            "Train Epoch: 0 [800/2994(27%)]\tTrain Loss: 0.451012\t runtime=12.2sec\n",
            "Train Epoch: 0 [880/2994(29%)]\tTrain Loss: 0.177615\t runtime=12.2sec\n",
            "Train Epoch: 0 [960/2994(32%)]\tTrain Loss: 0.324094\t runtime=12.2sec\n",
            "Train Epoch: 0 [1040/2994(35%)]\tTrain Loss: 0.212403\t runtime=12.2sec\n",
            "Train Epoch: 0 [1120/2994(37%)]\tTrain Loss: 0.264492\t runtime=12.2sec\n",
            "Train Epoch: 0 [1200/2994(40%)]\tTrain Loss: 0.370695\t runtime=12.2sec\n",
            "Train Epoch: 0 [1280/2994(43%)]\tTrain Loss: 0.064364\t runtime=12.2sec\n",
            "Train Epoch: 0 [1360/2994(45%)]\tTrain Loss: 0.177644\t runtime=12.2sec\n",
            "Train Epoch: 0 [1440/2994(48%)]\tTrain Loss: 0.043734\t runtime=12.2sec\n",
            "Train Epoch: 0 [1520/2994(51%)]\tTrain Loss: 0.060383\t runtime=12.2sec\n",
            "Train Epoch: 0 [1600/2994(53%)]\tTrain Loss: 0.357531\t runtime=12.2sec\n",
            "Train Epoch: 0 [1680/2994(56%)]\tTrain Loss: 0.299598\t runtime=12.2sec\n",
            "Train Epoch: 0 [1760/2994(59%)]\tTrain Loss: 0.140188\t runtime=12.2sec\n",
            "Train Epoch: 0 [1840/2994(61%)]\tTrain Loss: 0.164510\t runtime=12.2sec\n",
            "Train Epoch: 0 [1920/2994(64%)]\tTrain Loss: 0.202530\t runtime=12.2sec\n",
            "Train Epoch: 0 [2000/2994(67%)]\tTrain Loss: 0.189335\t runtime=12.2sec\n",
            "Train Epoch: 0 [2080/2994(69%)]\tTrain Loss: 0.217691\t runtime=12.2sec\n",
            "Train Epoch: 0 [2160/2994(72%)]\tTrain Loss: 0.321666\t runtime=12.2sec\n",
            "Train Epoch: 0 [2240/2994(75%)]\tTrain Loss: 0.363516\t runtime=12.2sec\n",
            "Train Epoch: 0 [2320/2994(77%)]\tTrain Loss: 0.210133\t runtime=12.2sec\n",
            "Train Epoch: 0 [2400/2994(80%)]\tTrain Loss: 0.428162\t runtime=12.2sec\n",
            "Train Epoch: 0 [2480/2994(83%)]\tTrain Loss: 0.083068\t runtime=12.2sec\n",
            "Train Epoch: 0 [2560/2994(86%)]\tTrain Loss: 0.059532\t runtime=12.2sec\n",
            "Train Epoch: 0 [2640/2994(88%)]\tTrain Loss: 0.099980\t runtime=12.2sec\n",
            "Train Epoch: 0 [2720/2994(91%)]\tTrain Loss: 0.106304\t runtime=12.2sec\n",
            "Train Epoch: 0 [2800/2994(94%)]\tTrain Loss: 0.212643\t runtime=12.2sec\n",
            "Train Epoch: 0 [2880/2994(96%)]\tTrain Loss: 0.125997\t runtime=12.2sec\n",
            "Train Epoch: 0 [2960/2994(99%)]\tTrain Loss: 0.111579\t runtime=12.2sec\n",
            "Train Epoch Takes 7.63min\n",
            "Train Epoch: 1 [0/2994(0%)]\tTrain Loss: 0.164833\t runtime=0.7sec\n",
            "Train Epoch: 1 [80/2994(3%)]\tTrain Loss: 0.149262\t runtime=12.2sec\n",
            "Train Epoch: 1 [160/2994(5%)]\tTrain Loss: 0.096729\t runtime=12.3sec\n",
            "Train Epoch: 1 [240/2994(8%)]\tTrain Loss: 0.346596\t runtime=12.2sec\n",
            "Train Epoch: 1 [320/2994(11%)]\tTrain Loss: 0.062121\t runtime=12.3sec\n",
            "Train Epoch: 1 [400/2994(13%)]\tTrain Loss: 0.129034\t runtime=12.2sec\n",
            "Train Epoch: 1 [480/2994(16%)]\tTrain Loss: 0.344572\t runtime=12.2sec\n",
            "Train Epoch: 1 [560/2994(19%)]\tTrain Loss: 0.085672\t runtime=12.2sec\n",
            "Train Epoch: 1 [640/2994(21%)]\tTrain Loss: 0.073319\t runtime=12.2sec\n",
            "Train Epoch: 1 [720/2994(24%)]\tTrain Loss: 0.182735\t runtime=12.2sec\n",
            "Train Epoch: 1 [800/2994(27%)]\tTrain Loss: 0.149431\t runtime=12.2sec\n",
            "Train Epoch: 1 [880/2994(29%)]\tTrain Loss: 0.169618\t runtime=12.2sec\n",
            "Train Epoch: 1 [960/2994(32%)]\tTrain Loss: 0.201212\t runtime=12.2sec\n",
            "Train Epoch: 1 [1040/2994(35%)]\tTrain Loss: 0.063465\t runtime=12.2sec\n",
            "Train Epoch: 1 [1120/2994(37%)]\tTrain Loss: 0.422923\t runtime=12.2sec\n",
            "Train Epoch: 1 [1200/2994(40%)]\tTrain Loss: 0.162005\t runtime=12.2sec\n",
            "Train Epoch: 1 [1280/2994(43%)]\tTrain Loss: 0.154949\t runtime=12.2sec\n",
            "Train Epoch: 1 [1360/2994(45%)]\tTrain Loss: 0.132995\t runtime=12.2sec\n",
            "Train Epoch: 1 [1440/2994(48%)]\tTrain Loss: 0.125404\t runtime=12.2sec\n",
            "Train Epoch: 1 [1520/2994(51%)]\tTrain Loss: 0.494610\t runtime=12.2sec\n",
            "Train Epoch: 1 [1600/2994(53%)]\tTrain Loss: 0.077485\t runtime=12.2sec\n",
            "Train Epoch: 1 [1680/2994(56%)]\tTrain Loss: 0.030583\t runtime=12.2sec\n",
            "Train Epoch: 1 [1760/2994(59%)]\tTrain Loss: 0.070725\t runtime=12.2sec\n",
            "Train Epoch: 1 [1840/2994(61%)]\tTrain Loss: 0.214779\t runtime=12.3sec\n",
            "Train Epoch: 1 [1920/2994(64%)]\tTrain Loss: 0.149377\t runtime=12.2sec\n",
            "Train Epoch: 1 [2000/2994(67%)]\tTrain Loss: 0.148626\t runtime=12.2sec\n",
            "Train Epoch: 1 [2080/2994(69%)]\tTrain Loss: 0.070679\t runtime=12.2sec\n",
            "Train Epoch: 1 [2160/2994(72%)]\tTrain Loss: 0.089530\t runtime=12.2sec\n",
            "Train Epoch: 1 [2240/2994(75%)]\tTrain Loss: 0.232111\t runtime=12.2sec\n",
            "Train Epoch: 1 [2320/2994(77%)]\tTrain Loss: 0.209864\t runtime=12.2sec\n",
            "Train Epoch: 1 [2400/2994(80%)]\tTrain Loss: 0.215311\t runtime=12.2sec\n",
            "Train Epoch: 1 [2480/2994(83%)]\tTrain Loss: 0.094045\t runtime=12.2sec\n",
            "Train Epoch: 1 [2560/2994(86%)]\tTrain Loss: 0.047466\t runtime=12.2sec\n",
            "Train Epoch: 1 [2640/2994(88%)]\tTrain Loss: 0.198378\t runtime=12.2sec\n",
            "Train Epoch: 1 [2720/2994(91%)]\tTrain Loss: 0.115628\t runtime=12.2sec\n",
            "Train Epoch: 1 [2800/2994(94%)]\tTrain Loss: 0.161577\t runtime=12.1sec\n",
            "Train Epoch: 1 [2880/2994(96%)]\tTrain Loss: 0.110477\t runtime=12.2sec\n",
            "Train Epoch: 1 [2960/2994(99%)]\tTrain Loss: 0.599408\t runtime=12.2sec\n",
            "Train Epoch Takes 7.62min\n",
            "Train Epoch: 2 [0/2994(0%)]\tTrain Loss: 0.013979\t runtime=0.7sec\n",
            "Train Epoch: 2 [80/2994(3%)]\tTrain Loss: 0.177571\t runtime=12.2sec\n",
            "Train Epoch: 2 [160/2994(5%)]\tTrain Loss: 0.038267\t runtime=12.2sec\n",
            "Train Epoch: 2 [240/2994(8%)]\tTrain Loss: 0.042896\t runtime=12.2sec\n",
            "Train Epoch: 2 [320/2994(11%)]\tTrain Loss: 0.389679\t runtime=12.3sec\n",
            "Train Epoch: 2 [400/2994(13%)]\tTrain Loss: 0.275754\t runtime=12.2sec\n",
            "Train Epoch: 2 [480/2994(16%)]\tTrain Loss: 0.066232\t runtime=12.2sec\n",
            "Train Epoch: 2 [560/2994(19%)]\tTrain Loss: 0.030187\t runtime=12.2sec\n",
            "Train Epoch: 2 [640/2994(21%)]\tTrain Loss: 0.060837\t runtime=12.2sec\n",
            "Train Epoch: 2 [720/2994(24%)]\tTrain Loss: 0.033315\t runtime=12.3sec\n",
            "Train Epoch: 2 [800/2994(27%)]\tTrain Loss: 0.001811\t runtime=12.3sec\n",
            "Train Epoch: 2 [880/2994(29%)]\tTrain Loss: 0.021412\t runtime=12.2sec\n",
            "Train Epoch: 2 [960/2994(32%)]\tTrain Loss: 0.072777\t runtime=12.2sec\n",
            "Train Epoch: 2 [1040/2994(35%)]\tTrain Loss: 0.185948\t runtime=12.2sec\n",
            "Train Epoch: 2 [1120/2994(37%)]\tTrain Loss: 0.069284\t runtime=12.3sec\n",
            "Train Epoch: 2 [1200/2994(40%)]\tTrain Loss: 0.026499\t runtime=12.3sec\n",
            "Train Epoch: 2 [1280/2994(43%)]\tTrain Loss: 0.071468\t runtime=12.2sec\n",
            "Train Epoch: 2 [1360/2994(45%)]\tTrain Loss: 0.013361\t runtime=12.2sec\n",
            "Train Epoch: 2 [1440/2994(48%)]\tTrain Loss: 0.072605\t runtime=12.2sec\n",
            "Train Epoch: 2 [1520/2994(51%)]\tTrain Loss: 0.019313\t runtime=12.2sec\n",
            "Train Epoch: 2 [1600/2994(53%)]\tTrain Loss: 0.031218\t runtime=12.2sec\n",
            "Train Epoch: 2 [1680/2994(56%)]\tTrain Loss: 0.040760\t runtime=12.2sec\n",
            "Train Epoch: 2 [1760/2994(59%)]\tTrain Loss: 0.044847\t runtime=12.2sec\n",
            "Train Epoch: 2 [1840/2994(61%)]\tTrain Loss: 0.094336\t runtime=12.2sec\n",
            "Train Epoch: 2 [1920/2994(64%)]\tTrain Loss: 0.091266\t runtime=12.2sec\n",
            "Train Epoch: 2 [2000/2994(67%)]\tTrain Loss: 0.048792\t runtime=12.2sec\n",
            "Train Epoch: 2 [2080/2994(69%)]\tTrain Loss: 0.047446\t runtime=12.3sec\n",
            "Train Epoch: 2 [2160/2994(72%)]\tTrain Loss: 0.151443\t runtime=12.2sec\n",
            "Train Epoch: 2 [2240/2994(75%)]\tTrain Loss: 0.040959\t runtime=12.3sec\n",
            "Train Epoch: 2 [2320/2994(77%)]\tTrain Loss: 0.082987\t runtime=12.2sec\n",
            "Train Epoch: 2 [2400/2994(80%)]\tTrain Loss: 0.089440\t runtime=12.2sec\n",
            "Train Epoch: 2 [2480/2994(83%)]\tTrain Loss: 0.025983\t runtime=12.2sec\n",
            "Train Epoch: 2 [2560/2994(86%)]\tTrain Loss: 0.013283\t runtime=12.2sec\n",
            "Train Epoch: 2 [2640/2994(88%)]\tTrain Loss: 0.103391\t runtime=12.2sec\n",
            "Train Epoch: 2 [2720/2994(91%)]\tTrain Loss: 0.036807\t runtime=12.2sec\n",
            "Train Epoch: 2 [2800/2994(94%)]\tTrain Loss: 0.026354\t runtime=12.2sec\n",
            "Train Epoch: 2 [2880/2994(96%)]\tTrain Loss: 0.051252\t runtime=12.2sec\n",
            "Train Epoch: 2 [2960/2994(99%)]\tTrain Loss: 0.031978\t runtime=12.2sec\n",
            "Train Epoch Takes 7.63min\n",
            "Train Epoch: 3 [0/2994(0%)]\tTrain Loss: 0.044746\t runtime=0.7sec\n",
            "Train Epoch: 3 [80/2994(3%)]\tTrain Loss: 0.019795\t runtime=12.2sec\n",
            "Train Epoch: 3 [160/2994(5%)]\tTrain Loss: 0.002596\t runtime=12.3sec\n",
            "Train Epoch: 3 [240/2994(8%)]\tTrain Loss: 0.063234\t runtime=12.2sec\n",
            "Train Epoch: 3 [320/2994(11%)]\tTrain Loss: 0.019710\t runtime=12.2sec\n",
            "Train Epoch: 3 [400/2994(13%)]\tTrain Loss: 0.016341\t runtime=12.2sec\n",
            "Train Epoch: 3 [480/2994(16%)]\tTrain Loss: 0.165278\t runtime=12.2sec\n",
            "Train Epoch: 3 [560/2994(19%)]\tTrain Loss: 0.162756\t runtime=12.2sec\n",
            "Train Epoch: 3 [640/2994(21%)]\tTrain Loss: 0.097236\t runtime=12.2sec\n",
            "Train Epoch: 3 [720/2994(24%)]\tTrain Loss: 0.208825\t runtime=12.2sec\n",
            "Train Epoch: 3 [800/2994(27%)]\tTrain Loss: 0.019424\t runtime=12.2sec\n",
            "Train Epoch: 3 [880/2994(29%)]\tTrain Loss: 0.022919\t runtime=12.2sec\n",
            "Train Epoch: 3 [960/2994(32%)]\tTrain Loss: 0.069361\t runtime=12.2sec\n",
            "Train Epoch: 3 [1040/2994(35%)]\tTrain Loss: 0.016063\t runtime=12.2sec\n",
            "Train Epoch: 3 [1120/2994(37%)]\tTrain Loss: 0.090576\t runtime=12.2sec\n",
            "Train Epoch: 3 [1200/2994(40%)]\tTrain Loss: 0.134924\t runtime=12.2sec\n",
            "Train Epoch: 3 [1280/2994(43%)]\tTrain Loss: 0.019355\t runtime=12.2sec\n",
            "Train Epoch: 3 [1360/2994(45%)]\tTrain Loss: 0.015333\t runtime=12.2sec\n",
            "Train Epoch: 3 [1440/2994(48%)]\tTrain Loss: 0.010906\t runtime=12.2sec\n",
            "Train Epoch: 3 [1520/2994(51%)]\tTrain Loss: 0.009843\t runtime=12.3sec\n",
            "Train Epoch: 3 [1600/2994(53%)]\tTrain Loss: 0.014337\t runtime=12.2sec\n",
            "Train Epoch: 3 [1680/2994(56%)]\tTrain Loss: 0.017883\t runtime=12.2sec\n",
            "Train Epoch: 3 [1760/2994(59%)]\tTrain Loss: 0.139272\t runtime=12.2sec\n",
            "Train Epoch: 3 [1840/2994(61%)]\tTrain Loss: 0.012972\t runtime=12.2sec\n",
            "Train Epoch: 3 [1920/2994(64%)]\tTrain Loss: 0.014626\t runtime=12.2sec\n",
            "Train Epoch: 3 [2000/2994(67%)]\tTrain Loss: 0.029661\t runtime=12.2sec\n",
            "Train Epoch: 3 [2080/2994(69%)]\tTrain Loss: 0.017144\t runtime=12.2sec\n",
            "Train Epoch: 3 [2160/2994(72%)]\tTrain Loss: 0.020444\t runtime=12.2sec\n",
            "Train Epoch: 3 [2240/2994(75%)]\tTrain Loss: 0.020805\t runtime=12.3sec\n",
            "Train Epoch: 3 [2320/2994(77%)]\tTrain Loss: 0.022692\t runtime=12.3sec\n",
            "Train Epoch: 3 [2400/2994(80%)]\tTrain Loss: 0.022083\t runtime=12.2sec\n",
            "Train Epoch: 3 [2480/2994(83%)]\tTrain Loss: 0.007753\t runtime=12.2sec\n",
            "Train Epoch: 3 [2560/2994(86%)]\tTrain Loss: 0.009111\t runtime=12.2sec\n",
            "Train Epoch: 3 [2640/2994(88%)]\tTrain Loss: 0.021882\t runtime=12.2sec\n",
            "Train Epoch: 3 [2720/2994(91%)]\tTrain Loss: 0.005915\t runtime=12.2sec\n",
            "Train Epoch: 3 [2800/2994(94%)]\tTrain Loss: 0.053777\t runtime=12.2sec\n",
            "Train Epoch: 3 [2880/2994(96%)]\tTrain Loss: 0.021727\t runtime=12.2sec\n",
            "Train Epoch: 3 [2960/2994(99%)]\tTrain Loss: 0.071895\t runtime=12.2sec\n",
            "Train Epoch Takes 7.64min\n",
            "Train Epoch: 4 [0/2994(0%)]\tTrain Loss: 0.013491\t runtime=0.7sec\n",
            "Train Epoch: 4 [80/2994(3%)]\tTrain Loss: 0.006869\t runtime=12.2sec\n",
            "Train Epoch: 4 [160/2994(5%)]\tTrain Loss: 0.010221\t runtime=12.2sec\n",
            "Train Epoch: 4 [240/2994(8%)]\tTrain Loss: 0.027383\t runtime=12.2sec\n",
            "Train Epoch: 4 [320/2994(11%)]\tTrain Loss: 0.018063\t runtime=12.2sec\n",
            "Train Epoch: 4 [400/2994(13%)]\tTrain Loss: 0.021835\t runtime=12.2sec\n",
            "Train Epoch: 4 [480/2994(16%)]\tTrain Loss: 0.065659\t runtime=12.2sec\n",
            "Train Epoch: 4 [560/2994(19%)]\tTrain Loss: 0.044837\t runtime=12.2sec\n",
            "Train Epoch: 4 [640/2994(21%)]\tTrain Loss: 0.072664\t runtime=12.2sec\n",
            "Train Epoch: 4 [720/2994(24%)]\tTrain Loss: 0.004566\t runtime=12.2sec\n",
            "Train Epoch: 4 [800/2994(27%)]\tTrain Loss: 0.011892\t runtime=12.2sec\n",
            "Train Epoch: 4 [880/2994(29%)]\tTrain Loss: 0.016052\t runtime=12.2sec\n",
            "Train Epoch: 4 [960/2994(32%)]\tTrain Loss: 0.048930\t runtime=12.2sec\n",
            "Train Epoch: 4 [1040/2994(35%)]\tTrain Loss: 0.005374\t runtime=12.2sec\n",
            "Train Epoch: 4 [1120/2994(37%)]\tTrain Loss: 0.050474\t runtime=12.1sec\n",
            "Train Epoch: 4 [1200/2994(40%)]\tTrain Loss: 0.013091\t runtime=12.2sec\n",
            "Train Epoch: 4 [1280/2994(43%)]\tTrain Loss: 0.126799\t runtime=12.1sec\n",
            "Train Epoch: 4 [1360/2994(45%)]\tTrain Loss: 0.006941\t runtime=12.2sec\n",
            "Train Epoch: 4 [1440/2994(48%)]\tTrain Loss: 0.071987\t runtime=12.2sec\n",
            "Train Epoch: 4 [1520/2994(51%)]\tTrain Loss: 0.058190\t runtime=12.1sec\n",
            "Train Epoch: 4 [1600/2994(53%)]\tTrain Loss: 0.002374\t runtime=12.2sec\n",
            "Train Epoch: 4 [1680/2994(56%)]\tTrain Loss: 0.068357\t runtime=12.2sec\n",
            "Train Epoch: 4 [1760/2994(59%)]\tTrain Loss: 0.002895\t runtime=12.2sec\n",
            "Train Epoch: 4 [1840/2994(61%)]\tTrain Loss: 0.043680\t runtime=12.2sec\n",
            "Train Epoch: 4 [1920/2994(64%)]\tTrain Loss: 0.019919\t runtime=12.2sec\n",
            "Train Epoch: 4 [2000/2994(67%)]\tTrain Loss: 0.002540\t runtime=12.2sec\n",
            "Train Epoch: 4 [2080/2994(69%)]\tTrain Loss: 0.001454\t runtime=12.2sec\n",
            "Train Epoch: 4 [2160/2994(72%)]\tTrain Loss: 0.014840\t runtime=12.2sec\n",
            "Train Epoch: 4 [2240/2994(75%)]\tTrain Loss: 0.023569\t runtime=12.2sec\n",
            "Train Epoch: 4 [2320/2994(77%)]\tTrain Loss: 0.011238\t runtime=12.2sec\n",
            "Train Epoch: 4 [2400/2994(80%)]\tTrain Loss: 0.011633\t runtime=12.2sec\n",
            "Train Epoch: 4 [2480/2994(83%)]\tTrain Loss: 0.007894\t runtime=12.2sec\n",
            "Train Epoch: 4 [2560/2994(86%)]\tTrain Loss: 0.012029\t runtime=12.2sec\n",
            "Train Epoch: 4 [2640/2994(88%)]\tTrain Loss: 0.026021\t runtime=12.2sec\n",
            "Train Epoch: 4 [2720/2994(91%)]\tTrain Loss: 0.060077\t runtime=12.2sec\n",
            "Train Epoch: 4 [2800/2994(94%)]\tTrain Loss: 0.006450\t runtime=12.2sec\n",
            "Train Epoch: 4 [2880/2994(96%)]\tTrain Loss: 0.128995\t runtime=12.2sec\n",
            "Train Epoch: 4 [2960/2994(99%)]\tTrain Loss: 0.021849\t runtime=12.1sec\n",
            "Train Epoch Takes 7.60min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xJjLyTf_UOO"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddw83cPeebbV"
      },
      "source": [
        "## 4. 추론"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErLNRzjQenVL"
      },
      "source": [
        "sub = pd.read_csv(\"/content/drive/MyDrive/LG_자연어/data/sample_submission.csv\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "govHm4-7_UOO"
      },
      "source": [
        "test_df_dataset = Summary_dataset(test_df_encodings, train_labels)\n",
        "test_df_dataloader = DataLoader(test_df_dataset, batch_size=2, num_workers=5)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw2FTTGgCcUi"
      },
      "source": [
        "def clean_text_2(text):\n",
        "    text = text.split(\"</s>\")[0]\n",
        "    text = text.replace(\"<s>\",\" \")\n",
        "    text = text.replace(\"<usr>\",\" \")\n",
        "    text = text.replace(\"<pad>\",\" \")\n",
        "    test = re.sub('<[a-zA-Z]+>',\" \",text)\n",
        "    text = text.replace(\"▁\",\" \")\n",
        "    text = re.sub(\"\\n\", ' ', text)\n",
        "    text = re.sub(\"\\xa0\", ' ', text)   \n",
        "    text = re.sub('<',' ',text)\n",
        "    text = re.sub('>',' ',text)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "\n",
        "    return text"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCAaqzlaFc1h"
      },
      "source": [
        "### 4-1 학습된 모델을 이용한 추론"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqNuem7d_UOP",
        "outputId": "1d78736a-13f4-48cc-bc50-b00549fb9f84"
      },
      "source": [
        "test_loss = 0\n",
        "correct = 0\n",
        "\n",
        "test_sum = []\n",
        "model.eval()\n",
        "for data in tqdm(test_df_dataloader):\n",
        "    \n",
        "    input_ = data['input_ids'].to(device)    \n",
        "    out = model.bart_model.generate(input_, max_length=500)\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    for i in range(len(out)):\n",
        "        text = tokenizer.convert_ids_to_tokens(out[i])\n",
        "        text = \"\".join(text)\n",
        "        text = clean_text_2(text)        \n",
        "        test_sum.append(text)\n",
        "\n",
        "\n",
        "sub.iloc[:,1] = test_sum"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 253/253 [02:17<00:00,  1.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjlzVgZ5f0sk"
      },
      "source": [
        "### 4-2 후처리\n",
        "- 특수문자 제거\n",
        "- 앞 뒤 공백 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm821Errex1s"
      },
      "source": [
        "sub[\"summary\"] = sub[\"summary\"].apply(clean_text_2)\n",
        "\n",
        "for i in range(len(sub['summary'])):\n",
        "    if sub['summary'][i][0] == ' ':\n",
        "        sub.loc[i,'summary'] = sub['summary'][i][1:]\n",
        "    if sub['summary'][i][-1] == ' ':\n",
        "        sub.loc[i,'summary'] = sub['summary'][i][:-1]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1TyizRTf6fM"
      },
      "source": [
        "### 4-3 출력 요약문 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP_oYMXVal0O",
        "outputId": "022a8e74-7607-43e6-a6ff-a3c379ea7325"
      },
      "source": [
        "# 출력 요약문 확인\n",
        "cnt = 0\n",
        "for i in sub['summary']:\n",
        "    print('%d번 요약문'%cnt)\n",
        "    print(i)\n",
        "    print()\n",
        "    cnt +=1\n",
        "    if cnt == 10:\n",
        "        break"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0번 요약문\n",
            "음성군의회 제235회 제1차 정례회 제1차 본회의 개의 선포.\n",
            "\n",
            "1번 요약문\n",
            "음성군의회 제235회 제1차 정례회 회기는 2012년 6월 21일부터 6월 28일까지 8일간으로 가결됨.\n",
            "\n",
            "2번 요약문\n",
            "제235회 제1차 정례회 회의록 서명의원으로 조천희 의원, 손달섭 의원이 선출됨.\n",
            "\n",
            "3번 요약문\n",
            "예산결산특별위원회 위원은 손수종 의원, 이한철 의원, 남궁유 의원, 조천희 의원, 손달섭 의원, 이대웅 의원, 김순옥 의원으로 구성함. 특별위원회는 6월 25일 하루동안 2011년도 예비비 지출 승인안, 2011회계 세입 세출 결산 승인안, 2011년도 회계 기금운용 성과분석보고 등을 회부하여 의사일정에 따라 심사하고자 구성함. 해당 안건은 가결됨.\n",
            "\n",
            "4번 요약문\n",
            "음성군 환경 분야의 현지확인 특별위원회 위원은 손수종 의원, 이한철 의원, 남궁유 의원, 조천희 의원, 손달섭 의원, 이대웅 의원, 김순옥 의원으로 구성함. 현지 확인 기간은 6월 27일부터 6월 28일까지 이틀간이며, 현지 확인 결과 결과보고는 제237회 임시회 본회의 시로 가결됨.\n",
            "\n",
            "5번 요약문\n",
            "주요사업 현지확인 결과보고서가 채택됨.\n",
            "\n",
            "6번 요약문\n",
            "제322회 음성군의회 임시회 제1차 본회의 개의 선포.\n",
            "\n",
            "7번 요약문\n",
            "제322회 음성군의회 임시회 회기는 4월 22일부터 4월 27일까지 6일간으로 가결됨.\n",
            "\n",
            "8번 요약문\n",
            "제322회 임시회 회의록 서명의원으로 김영섭 부의장, 김영호 의원이 선출됨.\n",
            "\n",
            "9번 요약문\n",
            "2020년도 제1회 세입 세출 추가경정예산안 및 기금운용계획 변경안 제안설명.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMkyVP4Qfm_U"
      },
      "source": [
        "### 4-4 결과 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOk_YHgj_UOQ"
      },
      "source": [
        "sub.to_csv(\"/content/drive/MyDrive/LG_자연어/submission/submission_f.csv\", index=False, encoding = 'utf-8')"
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}